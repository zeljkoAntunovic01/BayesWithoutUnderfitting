Task 2:
[X] 1. Play with null mask threshold 
[X] 2. Optimize the MSE sigma factor for the HEssian alculation: H = (1 / sigma) * I 
[X] 3. Steal the metrics from this paper https://arxiv.org/abs/2106.14806  (dont use the library, steal code instead)

Task 3:
[X] 1. Change the Hessian for the classification (read up on it, it will be idenitity + outer product predicted class probabilities (p @ p.T))
[X] 2. Implement metrics on the Sine curve first (non classification ones)
[X - not relevant] 3. Switch to alternating projections for Sine first and then others
[X] 4. 2D dataset to visualize the decision boundary
[X] 5. Implement metrics for the classification models

Task 4:
[X] 1. Make the 2D dataset less noisy
[X] 2. Switch to Alternating projections for the 2D dataset
[X] 3. Finish up the Q_PROJ and Q_LOSS with the naive appraoch by adding an identity matrix to the GGN so it can be decomposed via Eigenvalues
 
Task 5:
[X] 1. Optimize the projections code so that it is vectorized and does not instantiate big matrices (or any matrices)
[X] 2. Add a condition for convergence such as change in norm < 10e-4 or something
[X] 3. Run on MNIST

Task 6:
[X] 1. HPC run for MNIST and CIFAR10
[X] 2. Alpha estimation via the formula from the paper -> Trace is not easy so we need to figure out a fast way of calclating it
[X] 3. Do Eigenvalue/Eigvecs calculation in parallel for many batches at once, during the precomptuing of them (like JAX does)
[X] 4. AFter hPC run see how long it took and if we need to optimize it more

Task 7:
[X] 1. Debug the alpha, sometimes it is negative
[X] 2. Debug the alternating projections for MNIST and CIFAR10
[] 3. Read the paper again and find another use case/dataset to use the algorithm on

Task 8:
[X] 1. Calculate some (sum_of_eigen = eigenvalues.sum()) and then call (sum_of_eigen.backward()) to see if autodif engine will be called.
If it is called then you know that the JVPs and VJPs are saving computational graphs that are the reason you run out of memory. Do the same test
with Eigen vectors.

Task 9:
[X] 1. Print how long each step takes (each block of code and also each iteration seperately). Check if next iterations take longer because something might
accumulate such as memory and slows down next iterations. Check where the bottleneck is
[X] 2. If HPC is slower it might be that there is some memory copying between CPU and CUDA being done that slows it down
on HPC since HPC has a less powerful CPU. That could be the general bottleneck

Task 10:
[] 1. MNIST is only with 0.22 accuracy compared to 0.99 of MAP, with a fixed alpha = 10.0. This is a problem. 100 iterations is not enough 
and that is wrong.